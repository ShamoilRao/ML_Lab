{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zz7BcGCftH8P",
        "outputId": "286ba3f5-ca9c-4368-888d-614bfd3b1f7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_images.shape\n",
        "len(train_labels)\n",
        "train_labels\n",
        "test_images.shape\n",
        "len(test_labels)\n",
        "test_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQzBoqcItNJ8",
        "outputId": "54c653d7-f9e9-4a93-b996-46c424ad8f50"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Network Architecture"
      ],
      "metadata": {
        "id": "vlCRf9d2umTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "network = models.Sequential()\n",
        "# Dense(32) is a fully-connected layer with 32 hidden units.\n",
        "# in the first layer, you must specify the expected input data shape :\n",
        "# here, 28 X 28=784 -dimensional vectors.\n",
        "network.add(layers.Dense(32, activation='sigmoid', input_shape=(28 * 28, )))\n",
        "network.add(layers.Dense(8, activation='sigmoid'))\n",
        "network.add(layers.Dense(10, activation='softmax'))\n",
        "network.summary()\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-7uqGdVtYo8",
        "outputId": "591d7579-7b12-45ef-99c0-a56efed1a0af"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 32)                25120     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 264       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                90        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25474 (99.51 KB)\n",
            "Trainable params: 25474 (99.51 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Compilation Step"
      ],
      "metadata": {
        "id": "7JX2dFJRuhwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "network.compile(optimizer='sgd',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "PbfAh-6ptoEM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing the Image Data\n",
        "\n"
      ],
      "metadata": {
        "id": "GzpIavUOudsd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype('float32') / 255.\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype('float32') / 255.\n"
      ],
      "metadata": {
        "id": "WW6PQXM-tsa7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing the Labels"
      ],
      "metadata": {
        "id": "Bxztw3y8uY67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "train_labels = to_categorical(train_labels)\n",
        "train_labels\n",
        "test_labels = to_categorical(test_labels)\n",
        "test_labels\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gb84whqStvZX",
        "outputId": "2e07cf37-f405-4526-a212-3362d663feb1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and Testing"
      ],
      "metadata": {
        "id": "EDgER7i-uWy8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "network.fit(train_images, train_labels, epochs=160, batch_size=512)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufS1Mv3jtzj3",
        "outputId": "77d6132c-f7bb-49ff-8b7a-9fa092e8eb3f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/160\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 2.3356 - accuracy: 0.0939\n",
            "Epoch 2/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.3110 - accuracy: 0.0905\n",
            "Epoch 3/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.2987 - accuracy: 0.1503\n",
            "Epoch 4/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.2909 - accuracy: 0.1748\n",
            "Epoch 5/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.2848 - accuracy: 0.1715\n",
            "Epoch 6/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.2792 - accuracy: 0.1753\n",
            "Epoch 7/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.2738 - accuracy: 0.1902\n",
            "Epoch 8/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.2682 - accuracy: 0.2056\n",
            "Epoch 9/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.2624 - accuracy: 0.2193\n",
            "Epoch 10/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.2562 - accuracy: 0.2332\n",
            "Epoch 11/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.2496 - accuracy: 0.2433\n",
            "Epoch 12/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.2425 - accuracy: 0.2519\n",
            "Epoch 13/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.2349 - accuracy: 0.2681\n",
            "Epoch 14/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.2268 - accuracy: 0.2812\n",
            "Epoch 15/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.2180 - accuracy: 0.2959\n",
            "Epoch 16/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.2085 - accuracy: 0.3065\n",
            "Epoch 17/160\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 2.1983 - accuracy: 0.3220\n",
            "Epoch 18/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 2.1873 - accuracy: 0.3306\n",
            "Epoch 19/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 2.1755 - accuracy: 0.3425\n",
            "Epoch 20/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 2.1629 - accuracy: 0.3531\n",
            "Epoch 21/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 2.1493 - accuracy: 0.3590\n",
            "Epoch 22/160\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 2.1349 - accuracy: 0.3674\n",
            "Epoch 23/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 2.1195 - accuracy: 0.3749\n",
            "Epoch 24/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.1033 - accuracy: 0.3814\n",
            "Epoch 25/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.0861 - accuracy: 0.3888\n",
            "Epoch 26/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.0682 - accuracy: 0.3950\n",
            "Epoch 27/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.0493 - accuracy: 0.4012\n",
            "Epoch 28/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.0298 - accuracy: 0.4069\n",
            "Epoch 29/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.0096 - accuracy: 0.4128\n",
            "Epoch 30/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.9888 - accuracy: 0.4187\n",
            "Epoch 31/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.9674 - accuracy: 0.4244\n",
            "Epoch 32/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.9457 - accuracy: 0.4302\n",
            "Epoch 33/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.9237 - accuracy: 0.4374\n",
            "Epoch 34/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.9014 - accuracy: 0.4434\n",
            "Epoch 35/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.8790 - accuracy: 0.4516\n",
            "Epoch 36/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.8565 - accuracy: 0.4587\n",
            "Epoch 37/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.8341 - accuracy: 0.4675\n",
            "Epoch 38/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.8117 - accuracy: 0.4751\n",
            "Epoch 39/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.7894 - accuracy: 0.4852\n",
            "Epoch 40/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.7673 - accuracy: 0.4903\n",
            "Epoch 41/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.7453 - accuracy: 0.4973\n",
            "Epoch 42/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.7236 - accuracy: 0.5052\n",
            "Epoch 43/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.7022 - accuracy: 0.5113\n",
            "Epoch 44/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.6811 - accuracy: 0.5185\n",
            "Epoch 45/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 1.6602 - accuracy: 0.5254\n",
            "Epoch 46/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 1.6396 - accuracy: 0.5315\n",
            "Epoch 47/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 1.6194 - accuracy: 0.5370\n",
            "Epoch 48/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 1.5995 - accuracy: 0.5436\n",
            "Epoch 49/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 1.5800 - accuracy: 0.5488\n",
            "Epoch 50/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 1.5609 - accuracy: 0.5555\n",
            "Epoch 51/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.5421 - accuracy: 0.5603\n",
            "Epoch 52/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.5238 - accuracy: 0.5653\n",
            "Epoch 53/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.5058 - accuracy: 0.5718\n",
            "Epoch 54/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.4882 - accuracy: 0.5766\n",
            "Epoch 55/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.4711 - accuracy: 0.5823\n",
            "Epoch 56/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.4544 - accuracy: 0.5872\n",
            "Epoch 57/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.4381 - accuracy: 0.5930\n",
            "Epoch 58/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.4221 - accuracy: 0.5974\n",
            "Epoch 59/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.4066 - accuracy: 0.6030\n",
            "Epoch 60/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.3915 - accuracy: 0.6084\n",
            "Epoch 61/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.3768 - accuracy: 0.6139\n",
            "Epoch 62/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.3625 - accuracy: 0.6189\n",
            "Epoch 63/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.3485 - accuracy: 0.6240\n",
            "Epoch 64/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.3349 - accuracy: 0.6298\n",
            "Epoch 65/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.3216 - accuracy: 0.6337\n",
            "Epoch 66/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.3087 - accuracy: 0.6386\n",
            "Epoch 67/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.2961 - accuracy: 0.6425\n",
            "Epoch 68/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.2839 - accuracy: 0.6471\n",
            "Epoch 69/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.2719 - accuracy: 0.6517\n",
            "Epoch 70/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.2602 - accuracy: 0.6556\n",
            "Epoch 71/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.2488 - accuracy: 0.6595\n",
            "Epoch 72/160\n",
            "118/118 [==============================] - 1s 9ms/step - loss: 1.2377 - accuracy: 0.6639\n",
            "Epoch 73/160\n",
            "118/118 [==============================] - 1s 11ms/step - loss: 1.2268 - accuracy: 0.6668\n",
            "Epoch 74/160\n",
            "118/118 [==============================] - 1s 9ms/step - loss: 1.2161 - accuracy: 0.6706\n",
            "Epoch 75/160\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 1.2057 - accuracy: 0.6740\n",
            "Epoch 76/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 1.1955 - accuracy: 0.6772\n",
            "Epoch 77/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.1855 - accuracy: 0.6811\n",
            "Epoch 78/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.1758 - accuracy: 0.6844\n",
            "Epoch 79/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.1662 - accuracy: 0.6887\n",
            "Epoch 80/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.1568 - accuracy: 0.6914\n",
            "Epoch 81/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.1475 - accuracy: 0.6947\n",
            "Epoch 82/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.1385 - accuracy: 0.6976\n",
            "Epoch 83/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.1296 - accuracy: 0.7015\n",
            "Epoch 84/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.1209 - accuracy: 0.7046\n",
            "Epoch 85/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.1123 - accuracy: 0.7072\n",
            "Epoch 86/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.1039 - accuracy: 0.7098\n",
            "Epoch 87/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.0956 - accuracy: 0.7124\n",
            "Epoch 88/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.0874 - accuracy: 0.7158\n",
            "Epoch 89/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.0794 - accuracy: 0.7180\n",
            "Epoch 90/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.0715 - accuracy: 0.7202\n",
            "Epoch 91/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.0637 - accuracy: 0.7226\n",
            "Epoch 92/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.0561 - accuracy: 0.7255\n",
            "Epoch 93/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.0486 - accuracy: 0.7278\n",
            "Epoch 94/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.0412 - accuracy: 0.7301\n",
            "Epoch 95/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.0339 - accuracy: 0.7324\n",
            "Epoch 96/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.0267 - accuracy: 0.7349\n",
            "Epoch 97/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.0196 - accuracy: 0.7371\n",
            "Epoch 98/160\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 1.0127 - accuracy: 0.7394\n",
            "Epoch 99/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 1.0058 - accuracy: 0.7419\n",
            "Epoch 100/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.9990 - accuracy: 0.7440\n",
            "Epoch 101/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.9924 - accuracy: 0.7461\n",
            "Epoch 102/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.9858 - accuracy: 0.7480\n",
            "Epoch 103/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.9793 - accuracy: 0.7497\n",
            "Epoch 104/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.9729 - accuracy: 0.7518\n",
            "Epoch 105/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.9666 - accuracy: 0.7537\n",
            "Epoch 106/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.9604 - accuracy: 0.7557\n",
            "Epoch 107/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.9543 - accuracy: 0.7577\n",
            "Epoch 108/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.9483 - accuracy: 0.7593\n",
            "Epoch 109/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.9423 - accuracy: 0.7609\n",
            "Epoch 110/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.9364 - accuracy: 0.7632\n",
            "Epoch 111/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.9306 - accuracy: 0.7646\n",
            "Epoch 112/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.9249 - accuracy: 0.7665\n",
            "Epoch 113/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.9192 - accuracy: 0.7682\n",
            "Epoch 114/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.9137 - accuracy: 0.7700\n",
            "Epoch 115/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.9082 - accuracy: 0.7722\n",
            "Epoch 116/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.9027 - accuracy: 0.7729\n",
            "Epoch 117/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.8973 - accuracy: 0.7748\n",
            "Epoch 118/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.8920 - accuracy: 0.7760\n",
            "Epoch 119/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.8868 - accuracy: 0.7784\n",
            "Epoch 120/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.8816 - accuracy: 0.7796\n",
            "Epoch 121/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.8765 - accuracy: 0.7814\n",
            "Epoch 122/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.8715 - accuracy: 0.7836\n",
            "Epoch 123/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.8665 - accuracy: 0.7850\n",
            "Epoch 124/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.8616 - accuracy: 0.7867\n",
            "Epoch 125/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.8567 - accuracy: 0.7877\n",
            "Epoch 126/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.8519 - accuracy: 0.7891\n",
            "Epoch 127/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.8471 - accuracy: 0.7907\n",
            "Epoch 128/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.8424 - accuracy: 0.7919\n",
            "Epoch 129/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.8378 - accuracy: 0.7937\n",
            "Epoch 130/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.8331 - accuracy: 0.7946\n",
            "Epoch 131/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.8286 - accuracy: 0.7965\n",
            "Epoch 132/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.8241 - accuracy: 0.7979\n",
            "Epoch 133/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.8196 - accuracy: 0.7991\n",
            "Epoch 134/160\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.8152 - accuracy: 0.8005\n",
            "Epoch 135/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.8109 - accuracy: 0.8015\n",
            "Epoch 136/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.8066 - accuracy: 0.8028\n",
            "Epoch 137/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.8023 - accuracy: 0.8043\n",
            "Epoch 138/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7981 - accuracy: 0.8054\n",
            "Epoch 139/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7939 - accuracy: 0.8066\n",
            "Epoch 140/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7898 - accuracy: 0.8077\n",
            "Epoch 141/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7857 - accuracy: 0.8089\n",
            "Epoch 142/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7816 - accuracy: 0.8099\n",
            "Epoch 143/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7776 - accuracy: 0.8110\n",
            "Epoch 144/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7736 - accuracy: 0.8119\n",
            "Epoch 145/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7697 - accuracy: 0.8133\n",
            "Epoch 146/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7658 - accuracy: 0.8144\n",
            "Epoch 147/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7619 - accuracy: 0.8158\n",
            "Epoch 148/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7581 - accuracy: 0.8165\n",
            "Epoch 149/160\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.7543 - accuracy: 0.8174\n",
            "Epoch 150/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7505 - accuracy: 0.8184\n",
            "Epoch 151/160\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.7468 - accuracy: 0.8193\n",
            "Epoch 152/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.7431 - accuracy: 0.8208\n",
            "Epoch 153/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.7395 - accuracy: 0.8212\n",
            "Epoch 154/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.7359 - accuracy: 0.8225\n",
            "Epoch 155/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.7323 - accuracy: 0.8230\n",
            "Epoch 156/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.7287 - accuracy: 0.8241\n",
            "Epoch 157/160\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.7252 - accuracy: 0.8257\n",
            "Epoch 158/160\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.7217 - accuracy: 0.8259\n",
            "Epoch 159/160\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.7183 - accuracy: 0.8273\n",
            "Epoch 160/160\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.7148 - accuracy: 0.8279\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78efae447100>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}